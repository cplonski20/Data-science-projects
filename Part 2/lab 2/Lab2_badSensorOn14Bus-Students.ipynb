{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Detecting Bad Sensors in Power System Monitoring\n",
    "\n",
    "In this lab, our goal is to detect bad sensor data measured on the IEEE 14 bus test\n",
    "system shown below. The power flow equations that couple the voltages and power flows are \n",
    "nonlinear in nature, as discussed in class. We will load the sensor data from the\n",
    "file 'sensorData14Bus.csv', and utilize SVM to perform the bad data detection.\n",
    "We aim to understand how various parameters such as the nature of the corrupt data,\n",
    "the number of corrupt data, etc., affect our abilities to classify the data.\n",
    "\n",
    "<img src=\"IEEE14bus.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to call the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data \n",
    "\n",
    "Load the sensor data from the IEEE 14 bus test system, that has 14 buses\n",
    " and 20 branches. The data has been generated by adding a small noise\n",
    " to feasible voltages and power flows.\n",
    "     \n",
    "     Columns 1-14 contain bus voltage magnitudes.\n",
    "     \n",
    "     Columns 15-28 contain bus voltage phase angles.\n",
    "     \n",
    "     Columns 29-48 contain real power flow on all branches.\n",
    "     \n",
    "     Columns 49-68 contain reactive power flow on all branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n"
     ]
    }
   ],
   "source": [
    "nBuses = 14\n",
    "nBranches = 20\n",
    "\n",
    "# Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "# The '-1' makes them columns as per Python's convention of starting to number\n",
    "# from 0.\n",
    "busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "# Select the branches that you monitor.\n",
    "branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n",
    "columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                     branchesToSample + 48))\n",
    "\n",
    "# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "# with each column typecast as 'np.float32'.\n",
    "X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                  max_rows=5000)\n",
    "\n",
    "nDataPoints = np.shape(X)[0]\n",
    "nFeatures = np.shape(X)[1]\n",
    "\n",
    "print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "print(\"Number of data points = %d, number of features = %d\"\n",
    "      % (nDataPoints, nFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curroption Models \n",
    "\n",
    "Intentionally corrupt the first 'nCorrupt' rows of the data by adding\n",
    " a quantity to one or two sensor measurements that is not representative of\n",
    " our error model. We aim to study what nature of corruption is easier\n",
    " or difficult to detect.\n",
    " Specifically, we shall study 3 different models:\n",
    " \n",
    "     1. 'corruptionModel' = 1 : Add a random number with a bias to one of the measurements.\n",
    "     \n",
    "     2. 'corruptionModel' = 2 : Add a random number without bias to one of the measurements.\n",
    "     \n",
    "     3. 'corruptionModel' = 3 : Add a random number with a bias to both the measurements.\n",
    "     \n",
    "In all these cases, we will multiply the sensor data by either a uniform or a normal random number multiplied by 'multiplicationFactor'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a corruption model.\n",
    "nCorrupt = int(nDataPoints/3)\n",
    "corruptionModel = 1\n",
    "multiplicationFactor = 0.5\n",
    "\n",
    "# Choose which data to tamper with, that can be a voltage magnitude,\n",
    "# voltage phase angle, real power flow on a branch, reactive power flow\n",
    "# on a branch. We create functions to extract the relevant column to\n",
    "# corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "voltageMagnitudeColumn = lambda ii: ii\n",
    "\n",
    "voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "\n",
    "realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "# Encode two different kinds of columns to corrupt.\n",
    "# Option 1: Corrupt real power columns only.\n",
    "# Option 2: Corrupt real power and voltage magnitude.\n",
    "columnsToCorruptOption = 2\n",
    "\n",
    "if columnsToCorruptOption == 1:\n",
    "    columnsToCorrupt = [realPowerColumn(1),\n",
    "                        realPowerColumn(2)]\n",
    "else:\n",
    "    columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                        realPowerColumn(1)]\n",
    "\n",
    "# Corrupt the data appropriately, given the options.\n",
    "for index in range(nCorrupt):\n",
    "\n",
    "    if corruptionModel == 1:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "    elif corruptionModel == 2:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.randn())\n",
    "    else:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "        X[index, columnsToCorrupt[1]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is always a good practice to scale your data to run SVM. Notice that we are\n",
    " cheating a little when we scale the entire data set 'X', because our training and\n",
    " test sets are derived from 'X'. Ideally, one would have to scale the training\n",
    " and test sets separately. Create the appropriate labels and shuffle the lists 'X' and 'Y' together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "# 0's for the rest.\n",
    "Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "# Shuffle the features and the labels together.\n",
    "XY = list(zip(X, Y))\n",
    "np.random.shuffle(XY)\n",
    "X, Y = zip(*XY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the first lab that 'test_size' determines what fraction of the data becomes your test set.\n",
    "\n",
    "## Task 1 (10 points)\n",
    "\n",
    "Split the dataset into two parts: training and testing.\n",
    "Store the training set in the variables 'trainX' and 'trainY'.\n",
    " Store the testing set in the variables 'testX' and 'testY.\n",
    " Reserve 20% of the data for testing.\n",
    "The function 'train_test_split' may prove useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (10 points)\n",
    "\n",
    " Define the support vector machine classifier and train on the variables 'trainX' and 'trainY'. Use the SVC library from sklearn.svm. Only specify three hyper-parameters: 'kernel', 'degree', and 'max_iter'. Limit the maximum number of iterations to 100000 at the most. Set the kernel to be a linear classifier first. You may have to change it to report the results with other kernels. The parameter 'degree' specifies the degree for polynomial kernels. This parameter is not used for other kernels. The functions 'svm.SVC' and 'fit' will prove useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(degree=1, kernel=&#x27;linear&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=1, kernel=&#x27;linear&#x27;, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(degree=1, kernel='linear', max_iter=1000)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your code here\n",
    "model = svm.SVC(kernel = 'linear', degree= 1, max_iter= 1000)\n",
    "model.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (10 points)\n",
    "\n",
    "Predict the labels on the 'testX' dataset and store them in 'predictY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "predictY = model.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (10 points)\n",
    "\n",
    "Print the 'classification_report' to see how well 'predictY' matches with 'testY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97       675\n",
      "         1.0       0.94      0.95      0.94       325\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.96      0.96      0.96      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(classification_report(testY, predictY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print svm's internal accuracy score as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of SVM = 0.96\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(\"Accuracy score of SVM = %1.2f\" % model.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "We would like to compare 'classification_report' with this score for various runs. Let us consider the following cases: \n",
    "\n",
    "### Case 1:\n",
    "\n",
    "Only have sensor measurements from the first 5 branches. Choose option 1 in the 'columnsToCorruptOption'. Examine how well linear kernels perform when 'corruptionModel' = 1, 'corruptionModel' = 2, and 'corruptionModel'= 3. In case linear kernels do not perform well, you may try 'rbf' or polynomial kernels with degree 2.\n",
    "\n",
    "### Case 2:\n",
    "\n",
    "Choose 'corruptionModel = 1' with 'linear' kernel. Does it pay to monitor voltage magnitudes than power flows? In other words, do you consistently get better results when you choose 'columnsToCorruptOption' as 2? Make these judgements using the average score of at least 5 runs.\n",
    "\n",
    "\n",
    "#### Your task is to investigate the above two cases. You may add a few 'Markdown' and 'Code' cells below with your comments, code, and results. You can also report your results as a pandas DataFrame. You are free to report your results in your own way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94       676\n",
      "         1.0       0.85      0.92      0.88       324\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.90      0.92      0.91      1000\n",
      "weighted avg       0.92      0.92      0.92      1000\n",
      "\n",
      "Accuracy score of SVM = 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nBuses = 14\n",
    "nBranches = 20\n",
    "\n",
    "# Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "# The '-1' makes them columns as per Python's convention of starting to number\n",
    "# from 0.\n",
    "busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "# Select the branches that you monitor.\n",
    "branchesToSample = np.array([1, 5, 11, 17, 20]) - 1\n",
    "columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                     branchesToSample + 48))\n",
    "\n",
    "# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "# with each column typecast as 'np.float32'.\n",
    "X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                  max_rows=5000)\n",
    "\n",
    "nDataPoints = np.shape(X)[0]\n",
    "nFeatures = np.shape(X)[1]\n",
    " \n",
    "print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "print(\"Number of data points = %d, number of features = %d\"\n",
    "      % (nDataPoints, nFeatures))\n",
    "# Choose a corruption model.\n",
    "nCorrupt = int(nDataPoints/3)\n",
    "corruptionModel = 1\n",
    "multiplicationFactor = 0.5\n",
    "\n",
    "# Choose which data to tamper with, that can be a voltage magnitude,\n",
    "# voltage phase angle, real power flow on a branch, reactive power flow\n",
    "# on a branch. We create functions to extract the relevant column to\n",
    "# corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "voltageMagnitudeColumn = lambda ii: ii\n",
    "\n",
    "voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "\n",
    "realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "# Encode two different kinds of columns to corrupt.\n",
    "# Option 1: Corrupt real power columns only.\n",
    "# Option 2: Corrupt real power and voltage magnitude.\n",
    "columnsToCorruptOption = 1\n",
    "\n",
    "if columnsToCorruptOption == 1:\n",
    "    columnsToCorrupt = [realPowerColumn(1),\n",
    "                        realPowerColumn(2)]\n",
    "else:\n",
    "    columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                        realPowerColumn(1)]\n",
    "\n",
    "# Corrupt the data appropriately, given the options.\n",
    "for index in range(nCorrupt):\n",
    "\n",
    "    if corruptionModel == 1:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "    elif corruptionModel == 2:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.randn())\n",
    "    else:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "        X[index, columnsToCorrupt[1]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "\n",
    "\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "# 0's for the rest.\n",
    "Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "# Shuffle the features and the labels together.\n",
    "XY = list(zip(X, Y))\n",
    "np.random.shuffle(XY)\n",
    "X, Y = zip(*XY)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "model = svm.SVC(kernel = 'linear', degree= 1, max_iter= 1000)\n",
    "model.fit(trainX,trainY)\n",
    "predictY = model.predict(testX)\n",
    "print(classification_report(testY, predictY))\n",
    "print(\"Accuracy score of SVM = %1.2f\" % model.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      1.00      0.90       673\n",
      "         1.0       0.99      0.53      0.69       327\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.90      0.77      0.80      1000\n",
      "weighted avg       0.87      0.85      0.83      1000\n",
      "\n",
      "Accuracy score of SVM = 0.85\n"
     ]
    }
   ],
   "source": [
    "nBuses = 14\n",
    "nBranches = 20\n",
    "\n",
    "# Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "# The '-1' makes them columns as per Python's convention of starting to number\n",
    "# from 0.\n",
    "busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "# Select the branches that you monitor.\n",
    "branchesToSample = np.array([1, 5, 11, 17, 20]) - 1\n",
    "columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                     branchesToSample + 48))\n",
    "\n",
    "# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "# with each column typecast as 'np.float32'.\n",
    "X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                  max_rows=5000)\n",
    "\n",
    "nDataPoints = np.shape(X)[0]\n",
    "nFeatures = np.shape(X)[1]\n",
    " \n",
    "print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "print(\"Number of data points = %d, number of features = %d\"\n",
    "      % (nDataPoints, nFeatures))\n",
    "# Choose a corruption model.\n",
    "nCorrupt = int(nDataPoints/3)\n",
    "corruptionModel = 2\n",
    "multiplicationFactor = 0.5\n",
    "\n",
    "# Choose which data to tamper with, that can be a voltage magnitude,\n",
    "# voltage phase angle, real power flow on a branch, reactive power flow\n",
    "# on a branch. We create functions to extract the relevant column to\n",
    "# corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "voltageMagnitudeColumn = lambda ii: ii\n",
    "\n",
    "voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "\n",
    "realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "# Encode two different kinds of columns to corrupt.\n",
    "# Option 1: Corrupt real power columns only.\n",
    "# Option 2: Corrupt real power and voltage magnitude.\n",
    "columnsToCorruptOption = 1\n",
    "\n",
    "if columnsToCorruptOption == 1:\n",
    "    columnsToCorrupt = [realPowerColumn(1),\n",
    "                        realPowerColumn(2)]\n",
    "else:\n",
    "    columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                        realPowerColumn(1)]\n",
    "\n",
    "# Corrupt the data appropriately, given the options.\n",
    "for index in range(nCorrupt):\n",
    "\n",
    "    if corruptionModel == 1:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "    elif corruptionModel == 2:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.randn())\n",
    "    else:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "        X[index, columnsToCorrupt[1]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "\n",
    "\n",
    "\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "# 0's for the rest.\n",
    "Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "# Shuffle the features and the labels together.\n",
    "XY = list(zip(X, Y))\n",
    "np.random.shuffle(XY)\n",
    "X, Y = zip(*XY)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "model = svm.SVC(kernel = 'rbf', degree= 2, max_iter= 1000)\n",
    "model.fit(trainX,trainY)\n",
    "predictY = model.predict(testX)\n",
    "print(classification_report(testY, predictY))\n",
    "print(\"Accuracy score of SVM = %1.2f\" % model.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       675\n",
      "         1.0       0.97      0.94      0.96       325\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Accuracy score of SVM = 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nBuses = 14\n",
    "nBranches = 20\n",
    "\n",
    "# Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "# The '-1' makes them columns as per Python's convention of starting to number\n",
    "# from 0.\n",
    "busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "# Select the branches that you monitor.\n",
    "branchesToSample = np.array([1, 5, 11,17, 20]) - 1\n",
    "columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                     branchesToSample + 48))\n",
    "\n",
    "# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "# with each column typecast as 'np.float32'.\n",
    "X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                  max_rows=5000)\n",
    "\n",
    "nDataPoints = np.shape(X)[0]\n",
    "nFeatures = np.shape(X)[1]\n",
    " \n",
    "print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "print(\"Number of data points = %d, number of features = %d\"\n",
    "      % (nDataPoints, nFeatures))\n",
    "# Choose a corruption model.\n",
    "nCorrupt = int(nDataPoints/3)\n",
    "corruptionModel = 3\n",
    "multiplicationFactor = 0.5\n",
    "\n",
    "# Choose which data to tamper with, that can be a voltage magnitude,\n",
    "# voltage phase angle, real power flow on a branch, reactive power flow\n",
    "# on a branch. We create functions to extract the relevant column to\n",
    "# corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "voltageMagnitudeColumn = lambda ii: ii\n",
    "\n",
    "voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "\n",
    "realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "# Encode two different kinds of columns to corrupt.\n",
    "# Option 1: Corrupt real power columns only.\n",
    "# Option 2: Corrupt real power and voltage magnitude.\n",
    "columnsToCorruptOption = 1\n",
    "\n",
    "if columnsToCorruptOption == 1:\n",
    "    columnsToCorrupt = [realPowerColumn(1),\n",
    "                        realPowerColumn(2)]\n",
    "else:\n",
    "    columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                        realPowerColumn(1)]\n",
    "\n",
    "# Corrupt the data appropriately, given the options.\n",
    "for index in range(nCorrupt):\n",
    "\n",
    "    if corruptionModel == 1:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "    elif corruptionModel == 2:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.randn())\n",
    "    else:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "        X[index, columnsToCorrupt[1]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "\n",
    "\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "# 0's for the rest.\n",
    "Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "# Shuffle the features and the labels together.\n",
    "XY = list(zip(X, Y))\n",
    "np.random.shuffle(XY)\n",
    "X, Y = zip(*XY)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "model = svm.SVC(kernel = 'linear', degree= 1, max_iter= 1000)\n",
    "model.fit(trainX,trainY)\n",
    "predictY = model.predict(testX)\n",
    "print(classification_report(testY, predictY))\n",
    "print(\"Accuracy score of SVM = %1.2f\" % model.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1 Answers\n",
    "\n",
    "CorryptionModel #1 = For corruption model1 our training data is linearly seperable due to the fact that our random noise is biased to be only positive so a linear SVM seperates our data very well.  \n",
    "\n",
    "CorruptionModel #2 = For corruption model2 our training data is no longer linearly seperable due to the fact our random noise can be either positive or negative. If we use linearSVM we are essentially guessing and get roughly 50% accuracy. If we use RBF as a kernel function it is much easier to seperate our data  \n",
    "\n",
    "CorruptionModel #3 = For corruption model3 our training data is the most linearly seperable as we add biased noise to both of our features and because of this a linearSVM does best for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case2func(num):\n",
    "    nBuses = 14\n",
    "    nBranches = 20\n",
    "\n",
    "    # Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "    # The '-1' makes them columns as per Python's convention of starting to number\n",
    "    # from 0.\n",
    "    busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "    columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "    # Select the branches that you monitor.\n",
    "    branchesToSample = np.array([1, 5, 11, 17, 20]) - 1\n",
    "    columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                        branchesToSample + 48))\n",
    "\n",
    "    # Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "    # specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "    # separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "    # with each column typecast as 'np.float32'.\n",
    "    X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                    usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                    max_rows=5000)\n",
    "\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "    \n",
    "    print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "    print(\"Number of data points = %d, number of features = %d\"\n",
    "        % (nDataPoints, nFeatures))\n",
    "    # Choose a corruption model.\n",
    "    nCorrupt = int(nDataPoints/3)\n",
    "    corruptionModel = 1\n",
    "    multiplicationFactor = 0.5\n",
    "\n",
    "    # Choose which data to tamper with, that can be a voltage magnitude,\n",
    "    # voltage phase angle, real power flow on a branch, reactive power flow\n",
    "    # on a branch. We create functions to extract the relevant column to\n",
    "    # corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "    voltageMagnitudeColumn = lambda ii: ii\n",
    "\n",
    "    voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "\n",
    "    realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "    reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "    # Encode two different kinds of columns to corrupt.\n",
    "    # Option 1: Corrupt real power columns only.\n",
    "    # Option 2: Corrupt real power and voltage magnitude.\n",
    "    columnsToCorruptOption = num\n",
    "\n",
    "    if columnsToCorruptOption == 1:\n",
    "        columnsToCorrupt = [realPowerColumn(1),\n",
    "                            realPowerColumn(2)]\n",
    "    else:\n",
    "        columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                            realPowerColumn(1)]\n",
    "\n",
    "    # Corrupt the data appropriately, given the options.\n",
    "    for index in range(nCorrupt):\n",
    "\n",
    "        if corruptionModel == 1:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "        elif corruptionModel == 2:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.randn())\n",
    "        else:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "            X[index, columnsToCorrupt[1]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "\n",
    "\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "    # 0's for the rest.\n",
    "    Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "    # Shuffle the features and the labels together.\n",
    "    XY = list(zip(X, Y))\n",
    "    np.random.shuffle(XY)\n",
    "    X, Y = zip(*XY)\n",
    "\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    model = svm.SVC(kernel = 'linear', degree= 1, max_iter= 1000)\n",
    "    model.fit(trainX,trainY)\n",
    "    predictY = model.predict(testX)\n",
    "    temp = model.score(testX, testY)\n",
    "    # print(classification_report(testY, predictY))\n",
    "    # print(\"Accuracy score of SVM = %1.2f\" % model.score(testX, testY))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 20\n",
      "Columns to Corrupt 1 average accuracy:  0.9284000000000001\n",
      "Columns to Corrupt 2 average accuracy:  0.9735999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chazp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# print(case2func(1))\n",
    "# print(case2func(2))\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "for i in range(5):\n",
    "    sum1 += case2func(1)\n",
    "    sum2 += case2func(2)\n",
    "print(\"Columns to Corrupt 1 average accuracy: \", sum1/5)\n",
    "print(\"Columns to Corrupt 2 average accuracy: \", sum2/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we base our SVM off of both the real power and the voltagemagnitude we are able to be more accurate in our classification due to how we cover more variance with 2 different variables then we do with 1. It is easier to linearly seperate data when we only corrupt 2d data in 1 dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "424e43c892584a3934499bed8929b7e7dcffd929ec38f2a3206c0edb663973d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
